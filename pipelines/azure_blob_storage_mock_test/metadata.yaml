blocks:
- all_upstream_blocks_executed: true
  color: null
  configuration: {}
  downstream_blocks:
  - validation_of_input_data_a4a
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: Azure Blob Storage Load and Validate
  retry_config: null
  status: not_executed
  timeout: null
  type: transformer
  upstream_blocks: []
  uuid: azure_blob_storage_load_and_validate_a4a
- all_upstream_blocks_executed: false
  color: null
  configuration: {}
  downstream_blocks: []
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: Validation of Input Data
  retry_config: null
  status: not_executed
  timeout: null
  type: custom
  upstream_blocks:
  - azure_blob_storage_load_and_validate_a4a
  uuid: validation_of_input_data_a4a
cache_block_output_in_memory: false
callbacks: []
concurrency_config: {}
conditionals: []
created_at: '2025-06-24 20:26:38.816451+00:00'
created_by: freem124
data_integration: null
description: The data pipeline is designed to process and synchronize customer account
  user data by extracting information from azure blob storage, transforming it with
  custom logic, and loading it into the specified database schema and table. the pipeline
  ensures data validation through mage's unit testing framework, with a focus on verifying
  input data expectations and output correctness across transformation blocks.
executor_config: {}
executor_count: 1
executor_type: null
extensions: {}
name: Azure Blob Storage Mock Test
notification_config: {}
overrides: null
remote_variables_dir: null
retry_config: {}
run_pipeline_in_one_process: false
settings:
  triggers: null
spark_config: {}
state_store_config: {}
tags: []
type: python
uuid: azure_blob_storage_mock_test
variables_dir: /home/src/mage_data/cole-ws
widgets: []
